{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Supervised Learning: Regression Models and Performance Metrics\n",
        "\n",
        "#ASSIGNMENT"
      ],
      "metadata": {
        "id": "3e5qJYW_DlMQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.1 What is Simple Linear Regression (SLR)? Explain its purpose.\n",
        "\n",
        "     --> Simple Linear Regression (SLR) is a statistical method that models the relationship between a single independent (predictor) variable and a single dependent (outcome) variable by fitting a straight line to the data. Its purpose is to understand, predict, and quantify the linear relationship between the two variables, which can be used to make predictions and gain insights into how changes in the independent variable affect the dependent variable.\n",
        "\n",
        "     Purpose of Simple Linear Regression (SLR):\n",
        "\n",
        "     To establish a relationship between two variables: SLR helps determine if a linear relationship exists between an independent and a dependent variable and quantifies that relationship. For example, it can be used to see how monthly advertising cost (independent variable) relates to monthly sales (dependent variable).\n",
        "\n",
        "     To make predictions: Once the linear relationship is established, you can use the model to predict the value of the dependent variable for a new value of the independent variable. For instance, you could use the model to predict a car's resale price based on its age.\n",
        "\n",
        "     To gain insights and test hypotheses: The model provides a clear understanding of the relationship's direction and strength. The slope of the line (\\(\\beta _{1}\\)) shows the average change in the dependent variable for a one-unit increase in the independent variable, allowing for the testing of hypotheses about the relationship's significance.\n",
        "\n",
        "     To serve as a foundation for more complex models: Though simple, SLR is a fundamental technique in statistics and machine learning. Its principles form the basis for more advanced methods, such as multiple linear regression.\n",
        "\n"
      ],
      "metadata": {
        "id": "FEuY_r-xDk9D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.2 What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "     --> The key assumptions of simple linear regression are linearity, meaning the relationship between the variables is a straight line; independence, where errors are uncorrelated; homoscedasticity, or constant variance of errors; and normality, where the errors are normally distributed.\n"
      ],
      "metadata": {
        "id": "mBPNFiasEnFO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.3 Write the mathematical equation for a simple linear regression model and explain each term.\n",
        "\n",
        "     --> The mathematical equation for a simple linear regression model is \\(y=\\beta _{0}+\\beta _{1}x+\\epsilon \\), where \\(y\\) is the dependent variable, \\(x\\) is the independent variable, \\(\\beta _{0}\\) is the y-intercept, \\(\\beta _{1}\\) is the slope, and \\(\\epsilon \\) represents the error term.\n",
        "\n",
        "     Equation:\n",
        "\n",
        "      \\(y=\\beta _{0}+\\beta _{1}x+\\epsilon \\)\n",
        "\n",
        "     Explanation of terms:\n",
        "\n",
        "     \\(y\\): The dependent variable (or response variable) is the outcome you are trying to predict.\n",
        "\n",
        "     \\(\\beta _{0}\\): The intercept is the value of \\(y\\) when \\(x\\) is equal to zero. It is the point where the regression line crosses the vertical y-axis.\n",
        "\n",
        "     \\(\\beta _{1}\\): The slope (or regression coefficient) represents the change in the dependent variable (\\(y\\)) for a one-unit increase in the independent variable (\\(x\\)). It indicates the steepness of the line.\n",
        "\n",
        "     \\(\\epsilon \\): The error term (or residual) represents the difference between the observed value of \\(y\\) and the value predicted by the model. It accounts for the variability in \\(y\\) that is not explained by \\(x\\).    \n",
        "\n"
      ],
      "metadata": {
        "id": "HRgF7AyAEzjY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.4  Provide a real-world example where simple linear regression can be applied.\n",
        "\n",
        "     --> A real-world example of simple linear regression is predicting a house's price based on its size. By analyzing historical sales data, a company can create a model to see how much the price typically increases for each additional square foot, allowing them to predict the price of a new house based on its size.\n",
        "\n",
        "     Example: Predicting house prices\n",
        "\n",
        "     Scenario: A real estate company wants to estimate the likely selling price of a new house based on its square footage.\n",
        "\n",
        "     Independent variable: The size of the house in square feet (e.g., \\(x\\) represents the square footage).\n",
        "     \n",
        "     Dependent variable: The price of the house (e.g., \\(y\\) represents the price).\n",
        "     \n",
        "     Data: The company collects data from past house sales in a specific neighborhood, noting both the size and the final sale price for each house.\n",
        "     \n",
        "     Analysis: They use simple linear regression to find a line of best fit that shows the relationship between square footage and price. This line represents the average price increase for every extra square foot.\n",
        "     \n",
        "     Application: With this line, they can predict the price of a house with a certain square footage. For example, if the model indicates that houses in the area cost approximately \\(\\$100\\) per square foot, they can estimate that a 1,500-square-foot house would likely sell for around \\(\\$150,000\\) (\\(1500\\times 100\\))."
      ],
      "metadata": {
        "id": "KV7CZjYLGZcF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.5  What is the method of least squares in linear regression?\n",
        "\n",
        "     --> The method of least squares in linear regression is a statistical technique used to find the best-fit line for a set of data points by minimizing the sum of the squared differences between the observed values and the values predicted by the line. This is achieved by finding the equation (\\(y=mx+b\\)) that produces the smallest possible sum of squared residuals (errors), which are the vertical distances from each data point to the line."
      ],
      "metadata": {
        "id": "AvuKCdVUHISG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.6 What is Logistic Regression? How does it differ from Linear Regression?\n",
        "\n",
        "     --> Logistic regression predicts the probability of a categorical outcome (like yes/no) by modeling a sigmoidal function, while linear regression predicts a continuous value (like price or temperature) using a linear equation. The primary difference is the type of problem they solve: logistic is for classification and linear is for regression."
      ],
      "metadata": {
        "id": "9_y-3O2gHQbh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.7 Name and briefly describe three common evaluation metrics for regression models.\n",
        "\n",
        "     --> Three common regression metrics are Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared (\\(R^{2}\\)). MAE measures the average absolute difference between predicted and actual values, while MSE calculates the average of the squared differences, penalizing larger errors more heavily. \\(R^{2}\\) indicates the proportion of the variance in the dependent variable that is predictable from the independent variables.\n",
        "\n",
        "     1. Mean Absolute Error (MAE)\n",
        "\n",
        "     Description: The average absolute difference between the predicted and actual values.\n",
        "     \n",
        "     Formula: \\(\\text{MAE}=\\frac{1}{n}\\sum _{i=1}^{n}|y_{i}-\\^{y}_{i}|\\)\n",
        "     \n",
        "     Usefulness: It is easy to interpret because it is in the same units as the target variable.\n",
        "     \n",
        "     2. Mean Squared Error (MSE)\n",
        "     \n",
        "      Description: The average of the squared differences between predicted and actual values.\n",
        "     \n",
        "     Formula: \\(\\text{MSE}=\\frac{1}{n}\\sum _{i=1}^{n}(y_{i}-\\^{y}_{i})^{2}\\)\n",
        "     \n",
        "     Usefulness: It penalizes larger errors more significantly than MAE due to the squaring of the error term.\n",
        "     \n",
        "     3. R-squared (\\(R^{2}\\))\n",
        "     \n",
        "      Description: The coefficient of determination, which represents the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model.\n",
        "     \n",
        "     Range: It can range from \\(0\\) to \\(1\\), where a higher value indicates a better fit.\n",
        "     \n",
        "     Usefulness: It provides a relative measure of fit, showing how well the model's predictions are likely to be.\n"
      ],
      "metadata": {
        "id": "1SiaTah4Hbpq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.8 What is the purpose of the R-squared metric in regression analysis?\n",
        "\n",
        "     --> The purpose of the R-squared (R²) metric is to measure the goodness of fit for a regression model by indicating the proportion of variance in the dependent variable that is explained by the independent variables. Essentially, it tells you how well the model predicts the outcome, with a higher value (closer to 1 or 100%) indicating a better fit."
      ],
      "metadata": {
        "id": "2EinpNzXIEvD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.9 Write Python code to fit a simple linear regression model using scikit-learn and print the slope and intercept."
      ],
      "metadata": {
        "id": "ETxZX6zTISzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Sample data\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)  # Independent variable\n",
        "Y = np.array([2.1, 4.3, 6.1, 7.9, 10.2])      # Dependent variable\n",
        "\n",
        "# Create and fit the model\n",
        "model = LinearRegression()\n",
        "model.fit(X, Y)\n",
        "\n",
        "# Print the slope and intercept\n",
        "print(\"Slope (Coefficient):\", model.coef_[0])\n",
        "print(\"Intercept:\", model.intercept_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnzHdcc4IiNA",
        "outputId": "2d83f54f-3862-445a-9d1f-b202ecb46130"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slope (Coefficient): 1.9800000000000004\n",
            "Intercept: 0.17999999999999794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.10 How do you interpret the coefficients in a simple linear regression model?\n",
        "\n",
        "     --> In a simple linear regression model (\\(y=\\beta _{0}+\\beta _{1}x\\)), the coefficient \\(\\beta _{1}\\) represents the estimated change in the dependent variable (\\(y\\)) for a one-unit increase in the independent variable (\\(x\\)). The intercept, \\(\\beta _{0}\\), is the predicted value of \\(y\\) when \\(x\\) equals 0.\n",
        "\n",
        "     Interpreting the slope coefficient (\\(\\beta _{1}\\))\n",
        "\n",
        "     Direction: The sign of \\(\\beta _{1}\\) indicates the direction of the relationship.\n",
        "     \n",
        "     A positive coefficient means that as \\(x\\) increases, \\(y\\) is predicted to increase.\n",
        "     \n",
        "     A negative coefficient means that as \\(x\\) increases, \\(y\\) is predicted to decrease.\n",
        "\n",
        "     Magnitude: The value of \\(\\beta _{1}\\) tells you the size of the predicted change.\n",
        "     \n",
        "     For every one-unit increase in the independent variable (\\(x\\)), the dependent variable (\\(y\\)) is expected to change by the amount of the coefficient (\\(\\beta _{1}\\)).\n",
        "     \n",
        "     Example: If the equation is \\(Y=10+2X\\), a one-unit increase in \\(X\\) is associated with an estimated increase of \\(2\\) in \\(Y\\).\n",
        "\n",
        "     Interpreting the intercept coefficient (\\(\\beta _{0}\\))\n",
        "     \n",
        "      Meaning: The intercept is the predicted value of \\(y\\) when \\(x\\) is \\(0\\).\n",
        "     \n",
        "     Context is crucial: The intercept only has a meaningful interpretation if a value of \\(x=0\\) is realistic within the context of the data.\n",
        "     \n",
        "     Example: In a model predicting car stopping distance (\\(y\\)) based on speed (\\(x\\)), an intercept of \\(-17\\) feet is not physically possible. In such cases, the intercept is just a mathematical necessity to position the line and does not have a real-world meaning."
      ],
      "metadata": {
        "id": "cgWwtJ36Inz3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#END"
      ],
      "metadata": {
        "id": "oIX7CqAuJYkk"
      }
    }
  ]
}